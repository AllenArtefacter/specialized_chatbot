{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62bab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e81270",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Administrator\\Desktop\\abi_chatbot\\specialized_chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc9005c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index>=0.4.28"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\abi_chatbot\\\\specialized_chatbot\\\\.venv\\\\Lib\\\\site-packages\\\\pandas\\\\tests\\\\window\\\\test_expanding.py'\n",
      "Check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached llama_index-0.4.33-py3-none-any.whl\n",
      "Collecting langchain>=0.0.112\n",
      "  Using cached langchain-0.0.117-py3-none-any.whl (414 kB)\n",
      "Collecting openai==0.27.2\n",
      "  Using cached openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
      "Collecting unstructured\n",
      "  Using cached unstructured-0.5.4-py3-none-any.whl\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.8-py3-none-any.whl\n",
      "Requirement already satisfied: tensorflow in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from -r reqirement.txt (line 8)) (2.12.0rc1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from openai==0.27.2->-r reqirement.txt (line 3)) (2.28.2)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "Collecting dataclasses-json\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from llama-index>=0.4.28->-r reqirement.txt (line 1)) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.3.2-cp311-cp311-win_amd64.whl (578 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from langchain>=0.0.112->-r reqirement.txt (line 2)) (6.0)\n",
      "Collecting SQLAlchemy<2,>=1\n",
      "  Using cached SQLAlchemy-1.4.47-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.6-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from wikipedia->-r reqirement.txt (line 4)) (4.12.0)\n",
      "Collecting argilla\n",
      "  Using cached argilla-1.4.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-9.4.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Collecting pypandoc\n",
      "  Using cached pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-0.8.11-py3-none-any.whl\n",
      "Collecting python-pptx\n",
      "  Using cached python_pptx-0.6.21-py3-none-any.whl\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: markdown in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from unstructured->-r reqirement.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from unstructured->-r reqirement.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0-rc1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow->-r reqirement.txt (line 8)) (2.12.0rc1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (67.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.51.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0rc0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0rc0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.31.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r reqirement.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r reqirement.txt (line 3)) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r reqirement.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r reqirement.txt (line 3)) (1.26.15)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp311-cp311-win_amd64.whl (192 kB)\n",
      "Collecting httpx<0.24,>=0.15\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting deprecated~=1.2.0\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting backoff\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting rich<=13.0.1\n",
      "  Using cached rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from pandas->llama-index>=0.4.28->-r reqirement.txt (line 1)) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tqdm->openai==0.27.2->-r reqirement.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia->-r reqirement.txt (line 4)) (2.4)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.10.31-cp311-cp311-win_amd64.whl (267 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Using cached XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.38.4)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured->-r reqirement.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.10.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from rich<=13.0.1->argilla->unstructured->-r reqirement.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.2.3)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured->-r reqirement.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow->-r reqirement.txt (line 8)) (3.2.2)\n",
      "Installing collected packages: rfc3986, pytz, monotonic, docx2txt, commonmark, XlsxWriter, tqdm, tenacity, rich, regex, python-magic, PyPDF2, pypandoc, pydantic, pillow, mypy-extensions, multidict, marshmallow, lxml, joblib, h11, greenlet, frozenlist, et-xmlfile, deprecated, click, backoff, async-timeout, yarl, wikipedia, typing-inspect, tiktoken, SQLAlchemy, python-pptx, python-docx, pandas, openpyxl, nltk, marshmallow-enum, httpcore, aiosignal, httpx, dataclasses-json, aiohttp, openai, langchain, argilla, unstructured, llama-index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index>=0.4.28\n",
      "  Using cached llama_index-0.4.33.tar.gz (147 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting langchain>=0.0.112\n",
      "  Using cached langchain-0.0.117-py3-none-any.whl (414 kB)\n",
      "Collecting openai==0.27.2\n",
      "  Using cached openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting unstructured\n",
      "  Using cached unstructured-0.5.4.tar.gz (1.3 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tensorflow>=2.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from -r reqirement.txt (line 8)) (2.12.0rc1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from openai==0.27.2->-r reqirement.txt (line 3)) (2.28.2)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "Collecting dataclasses_json\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from llama-index>=0.4.28->-r reqirement.txt (line 1)) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.3.2-cp311-cp311-win_amd64.whl (578 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from langchain>=0.0.112->-r reqirement.txt (line 2)) (6.0)\n",
      "Collecting SQLAlchemy<2,>=1\n",
      "  Downloading SQLAlchemy-1.4.47-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.6 MB 163.8 kB/s eta 0:00:10\n",
      "      --------------------------------------- 0.0/1.6 MB 163.8 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.0/1.6 MB 178.6 kB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.1/1.6 MB 217.9 kB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.1/1.6 MB 269.5 kB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.1/1.6 MB 312.2 kB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.1/1.6 MB 312.9 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.2/1.6 MB 392.8 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.2/1.6 MB 436.8 kB/s eta 0:00:04\n",
      "     ------ --------------------------------- 0.2/1.6 MB 502.2 kB/s eta 0:00:03\n",
      "     ------- -------------------------------- 0.3/1.6 MB 553.0 kB/s eta 0:00:03\n",
      "     -------- ------------------------------- 0.3/1.6 MB 617.8 kB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.5/1.6 MB 761.8 kB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.5/1.6 MB 822.6 kB/s eta 0:00:02\n",
      "     -------------- ------------------------- 0.6/1.6 MB 857.2 kB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 0.6/1.6 MB 922.8 kB/s eta 0:00:02\n",
      "     ------------------ --------------------- 0.7/1.6 MB 975.2 kB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.8/1.6 MB 1.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.0/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.2/1.6 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.4/1.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.6 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.6-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from wikipedia->-r reqirement.txt (line 4)) (4.12.0)\n",
      "Collecting argilla\n",
      "  Using cached argilla-1.4.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-9.4.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Collecting pypandoc\n",
      "  Using cached pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-0.8.11-py3-none-any.whl\n",
      "Collecting python-pptx\n",
      "  Using cached python_pptx-0.6.21-py3-none-any.whl\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: markdown in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from unstructured->-r reqirement.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from unstructured->-r reqirement.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0-rc1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow>=2.0->-r reqirement.txt (line 8)) (2.12.0rc1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (67.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.51.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0rc0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0rc0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.31.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r reqirement.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r reqirement.txt (line 3)) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r reqirement.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r reqirement.txt (line 3)) (1.26.15)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp311-cp311-win_amd64.whl (192 kB)\n",
      "Collecting httpx<0.24,>=0.15\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting deprecated~=1.2.0\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting backoff\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting rich<=13.0.1\n",
      "  Using cached rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from pandas->llama-index>=0.4.28->-r reqirement.txt (line 1)) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tqdm->openai==0.27.2->-r reqirement.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia->-r reqirement.txt (line 4)) (2.4)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.10.31-cp311-cp311-win_amd64.whl (267 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Using cached XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.38.4)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured->-r reqirement.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.10.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from rich<=13.0.1->argilla->unstructured->-r reqirement.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.2.3)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured->-r reqirement.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0-rc1->tensorflow>=2.0->-r reqirement.txt (line 8)) (3.2.2)\n",
      "Building wheels for collected packages: llama-index, wikipedia, unstructured, docx2txt\n",
      "  Building wheel for llama-index (setup.py): started\n",
      "  Building wheel for llama-index (setup.py): finished with status 'done'\n",
      "  Created wheel for llama-index: filename=llama_index-0.4.33-py3-none-any.whl size=218562 sha256=22a51f2d3f71ece6d60b9460c0ab27965db0ce04db853591e8c96deda13acaf2\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\22\\4c\\bf\\596b29dea6807c15cc2bc85e88ccf2f5b5b8ef695bf197c874\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11707 sha256=711d691138d48ff18b51ff07db85a8ea19a4a6bfdf880ec946d3ba201d9e9b46\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "  Building wheel for unstructured (setup.py): started\n",
      "  Building wheel for unstructured (setup.py): finished with status 'done'\n",
      "  Created wheel for unstructured: filename=unstructured-0.5.4-py3-none-any.whl size=1314354 sha256=9174a92b0ef838a2d04d33a4aca2f829f8b442c59d1f38c6142b3af9c21f3f6c\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\cb\\a8\\5b\\8a0499036c19c67e13544fd3a4f3fa04bb12eb0ed8791935db\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3973 sha256=493b6202ab74638193d68b5c53af936b77f8688cf21355c7b179a787c8219cf4\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\0f\\0e\\7a\\3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "Successfully built llama-index wikipedia unstructured docx2txt\n",
      "Installing collected packages: rfc3986, pytz, monotonic, docx2txt, commonmark, XlsxWriter, tqdm, tenacity, rich, regex, python-magic, PyPDF2, pypandoc, pydantic, pillow, mypy-extensions, multidict, marshmallow, lxml, joblib, h11, greenlet, frozenlist, et-xmlfile, deprecated, click, backoff, async-timeout, yarl, wikipedia, typing-inspect, tiktoken, SQLAlchemy, python-pptx, python-docx, pandas, openpyxl, nltk, marshmallow-enum, httpcore, aiosignal, httpx, dataclasses_json, aiohttp, openai, langchain, argilla, unstructured, llama-index\n",
      "Successfully installed PyPDF2-3.0.1 SQLAlchemy-1.4.47 XlsxWriter-3.0.9 aiohttp-3.8.4 aiosignal-1.3.1 argilla-1.4.0 async-timeout-4.0.2 backoff-2.2.1 click-8.1.3 commonmark-0.9.1 dataclasses_json-0.5.7 deprecated-1.2.13 docx2txt-0.8 et-xmlfile-1.1.0 frozenlist-1.3.3 greenlet-2.0.2 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 joblib-1.2.0 langchain-0.0.117 llama-index-0.4.33 lxml-4.9.2 marshmallow-3.19.0 marshmallow-enum-1.5.1 monotonic-1.6 multidict-6.0.4 mypy-extensions-1.0.0 nltk-3.8.1 openai-0.27.2 openpyxl-3.1.2 pandas-1.5.3 pillow-9.4.0 pydantic-1.10.6 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 pytz-2022.7.1 regex-2022.10.31 rfc3986-1.5.0 rich-13.0.1 tenacity-8.2.2 tiktoken-0.3.2 tqdm-4.65.0 typing-inspect-0.8.0 unstructured-0.5.4 wikipedia-1.4.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r reqirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "740138e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open('../config.json'))\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e363f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1a28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Sequence, Type, cast, Union\n",
    "import logging\n",
    "import json\n",
    "import json\n",
    "from langchain import OpenAI\n",
    "\n",
    "from llama_index.indices.vector_store.base import GPTVectorStoreIndex\n",
    "from llama_index.vector_stores import (\n",
    "    ChromaVectorStore,\n",
    "    FaissVectorStore,\n",
    "    PineconeVectorStore,\n",
    "    QdrantVectorStore,\n",
    "    SimpleVectorStore,\n",
    "    WeaviateVectorStore,\n",
    ")\n",
    "from llama_index import (\n",
    "    GPTSimpleVectorIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    WikipediaReader,\n",
    "    GPTListIndex,\n",
    "    GPTKeywordTableIndex,\n",
    "    GPTSimpleKeywordTableIndex,\n",
    "    LLMPredictor, GPTSimpleVectorIndex, PromptHelper,\n",
    "    QuestionAnswerPrompt\n",
    ")\n",
    "from llama_index.indices.query.vector_store.queries import (\n",
    "    GPTChromaIndexQuery,\n",
    "    GPTFaissIndexQuery,\n",
    "    GPTSimpleVectorIndexQuery,\n",
    "\n",
    ")\n",
    "from langchain.agents import initialize_agent, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0b0e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"text-davinci-003\"\n",
    "\n",
    "LLM = OpenAI(\n",
    "    temperature=0,\n",
    "    model_name=MODEL,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "LLM_PREDICTOR = LLMPredictor(llm=LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05eae09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1019057",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = [\n",
    "    \"Heineken\",\n",
    "    \"Molson Coors\", \n",
    "    \"Carlsberg\", \n",
    "    \"Constellation\",\n",
    "    \"Pabst Brewing\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4ed1e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"You are an expert to beer and be glad to recommand beer \\n\"\n",
    "    \"Given the context information and not prior knowledge, answer the question as trully as possible, if the question beer brands is not contained in the context, say 'sorry I don't know' \\n\"\n",
    "    f\"If your answer might contains anything about {','.join(competitors)}, please do say 'Sorry I don't know\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Context: {context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Please use the same language\"\n",
    "    \"{query_str}\"\n",
    ")\n",
    "\n",
    "DEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "456e7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('../data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0eaf122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 61763 tokens\n"
     ]
    }
   ],
   "source": [
    "bot = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "def2a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 618 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry I don't know\n",
      "[SourceNode(source_text='Kwak provides following products: Kwak Amber, Kwak Blonde, Kwak Rouge\\n\\n\\nBrand Introduction\\nPauwel Kwak was a brewer and owner of the De Hoorn Inn in Dendermonde at the time of Napoleon. He was also a very inventive innkeeper.\\nDuring those times, coachmen who stopped at an inn were not allowed to leave their coach and horses in order to have their thirst quenched, unlike their passengers. So Pauwel Kwak came up with an ingenious solution. He commissioned a special Kwak glass to be blown, a glass that could be hung safely on a coach. Allowing any coachman who visited his inn to enjoy a Kwak glass of beer like everyone else. His invention was a runaway success.\\nIn 1982 inspired by this tale, Ivo Bosteels created a special Pauwel Kwak amber beer and recreated his iconic glass design, so that the legacy of this unconventional genius continues to be enjoyed today.\\nIn 2022 the Kwak range expanded and the original Kwak Amber beer was joined by two new beers: Kwak Blonde and Kwak Rouge.\\n\\n\\nBrand Products\\nKwak Amber\\nKwak is a traditional strong Belgian amber ale, a perfect blend of malt and hops with a wonderful complexity of flavour. Original in its light amber colour with a full and velvety head, is this an ale with a beautiful explosion in the mouth of biscuit, banana, orange marmalade, hints of caramel and spices to end in a delicate bitterness.\\nABV: 8.4%\\nAroma: biscuit, banana, caramel, orange marmelade, spice, delicate bitterness\\n\\nKwak Blonde\\nKwak Blonde is a smooth and refreshing blonde beer, with delicate bitterness and subtle hints of aroma hops, a firm head and, above all, the characteristic fruitiness of the Kwak yeast, expressed in hints of banana and pear.\\nABV: 7.4%\\nAroma: delicate bitterness, banana, pear\\n\\nKwak Rouge\\nKwak rouge is a refreshing specialty beer with notes of cherry and almond, based on the unique Kwak recipe. Subtly bitter, slightly sweet and full of flavour.\\nABV: 8%\\nAroma: delicate bitterness, cherry, almond ', doc_id='e412f29c-f030-423a-86a9-5cc2913f34af', extra_info=None, node_info={'start': 0, 'end': 1964}, similarity=0.8113818666150556, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('prompt:Recommand some beer from Heineken\\nresponse:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83f2cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1250 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 19 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry I don't know.\n",
      "[SourceNode(source_text='-Introduction\\n190030\\n2015BrandZ100BrandZ2019Brand Finance\\nHarbin Brewery was established in 1900 and was the oldest brewery brand in China. Harbin always prioritize brand quality and its products are sold all over the country and even more than 30 overseas countries and areas. As a famous beer brand for young people, Harbin Brewery has beeing building deeper relationship with the young through hip-hop, sports, fashion, esports and others, and now become the most popular brand among young people.\\nIn 2015, Harbin Brewery was listed in the BrandZ top 100 most valuable brand in China and the fastest growing beer brand, also the market value was increasing stably. In 2019, Harbin Brewery was listed as the fourth most valuable brand in the world by Brand Finance, and was the only Chinese local brand among top five.\\n\\n-CustomerReviewFromJingdong\\n--\\n--\\n--', doc_id='206db893-82a0-4186-b800-14711b904b8c', extra_info=None, node_info={'start': 0, 'end': 1263}, similarity=0.8118999465164335, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Question:Heineken\\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0399e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 632 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Molson Coors,Carlsberg,Constellation,Pabst Brewing\n",
      "Sorry, I don't know.\n",
      "[SourceNode(source_text='Kwak provides following products: Kwak Amber, Kwak Blonde, Kwak Rouge\\n\\n\\nBrand Introduction\\nPauwel Kwak was a brewer and owner of the De Hoorn Inn in Dendermonde at the time of Napoleon. He was also a very inventive innkeeper.\\nDuring those times, coachmen who stopped at an inn were not allowed to leave their coach and horses in order to have their thirst quenched, unlike their passengers. So Pauwel Kwak came up with an ingenious solution. He commissioned a special Kwak glass to be blown, a glass that could be hung safely on a coach. Allowing any coachman who visited his inn to enjoy a Kwak glass of beer like everyone else. His invention was a runaway success.\\nIn 1982 inspired by this tale, Ivo Bosteels created a special Pauwel Kwak amber beer and recreated his iconic glass design, so that the legacy of this unconventional genius continues to be enjoyed today.\\nIn 2022 the Kwak range expanded and the original Kwak Amber beer was joined by two new beers: Kwak Blonde and Kwak Rouge.\\n\\n\\nBrand Products\\nKwak Amber\\nKwak is a traditional strong Belgian amber ale, a perfect blend of malt and hops with a wonderful complexity of flavour. Original in its light amber colour with a full and velvety head, is this an ale with a beautiful explosion in the mouth of biscuit, banana, orange marmalade, hints of caramel and spices to end in a delicate bitterness.\\nABV: 8.4%\\nAroma: biscuit, banana, caramel, orange marmelade, spice, delicate bitterness\\n\\nKwak Blonde\\nKwak Blonde is a smooth and refreshing blonde beer, with delicate bitterness and subtle hints of aroma hops, a firm head and, above all, the characteristic fruitiness of the Kwak yeast, expressed in hints of banana and pear.\\nABV: 7.4%\\nAroma: delicate bitterness, banana, pear\\n\\nKwak Rouge\\nKwak rouge is a refreshing specialty beer with notes of cherry and almond, based on the unique Kwak recipe. Subtly bitter, slightly sweet and full of flavour.\\nABV: 8%\\nAroma: delicate bitterness, cherry, almond ', doc_id='e412f29c-f030-423a-86a9-5cc2913f34af', extra_info=None, node_info={'start': 0, 'end': 1964}, similarity=0.8193211638797565, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Recommand some beer from Heineken', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8094c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4208 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 13 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Yes, Corona is a brand of beer produced by Mexican brewery Cervecera Modelo and owned by Belgian company AB InBev. It is the top-selling brand of imported beer in the United States and is also popular in Mexico, where it is the official beer of both the NASCAR PEAK Mexico and NASCAR Cup Series. It is often served with a wedge of lime or lemon in the neck of the bottle to add tartness and flavor. The recipe for the mash bill includes corn as well as the barley malt and hops traditionally used for making beer. The brand's most popular variation is Corona Extra, a pale lager. It is one of the top-selling beers worldwide, and Corona Extra has been the top-selling imported drink in the U.S. since 1998.Other variants of the Corona beer brand include Corona Light, Corona Premier, and Corona Familiar. A variety of flavored hard seltzers marketed under the Corona brand name was launched in March 2020.\n",
      "[SourceNode(source_text='Summary\\nCorona (beer)\\nCorona is a brand of beer produced by Mexican brewery Cervecera Modelo and owned by Belgian company AB InBev. It is the top-selling brand of imported beer in the United States. It is often served with a wedge of lime or lemon in the neck of the bottle to add tartness and flavor. The recipe for the mash bill includes corn as well as the barley malt and hops traditionally used for making beer.\\nThe brand\\'s most popular variation is Corona Extra, a pale lager. It is one of the top-selling beers worldwide, and Corona Extra has been the top-selling imported drink in the U.S. since 1998.Other variants of the Corona beer brand include Corona Light, Corona Premier, and Corona Familiar. A variety of flavored hard seltzers marketed under the Corona brand name was launched in March 2020.\\n\\nIngredients\\nCorona (beer)\\nAccording to Sinebrychoff, a Finnish company owned by the Carlsberg Group, Corona Extra contains barley malt, corn, hops, yeast, antioxidants (ascorbic acid), and propylene glycol alginate as a stabilizer.\\n\\nPackaging\\nCorona (beer)\\nCorona beer is available in a variety of bottle presentations, ranging from the 207 ml (7.0 U.S. fl oz; 7.3 imp fl oz) ampolleta (labeled Coronita and just referred as the cuartito) up to the 940 ml (31.8 U.S. fl oz; 33.1 imp fl oz) Corona Familiar (known as the familiar, Litro or Mega). A draught version also exists, as does canned Corona in some markets.\\nIn Spain, the beer is branded as Coronita (literally, \\'little crown\\'), as winemaker Bodegas Torres has owned the trademark for \"Coronas\" since 1907. The packaging is otherwise the same in Spain as in Mexico and the United States. In the United Kingdom, Canada, Australia, and the United States, smaller, 210ml (7 fl. oz) bottles of the beer are also branded as \"Coronita\".\\n\\nSponsorship partners\\nCorona (beer)\\nCorona was a longtime sponsor of boxing in Mexico, including sponsorship of Saturday night fights on Televisa, but reduced its sponsorship after Anheuser-Busch InBev took full control of the brand. In the United States, Constellation Brands continues to sponsor boxing through Corona, most notably with undefeated featherweight champion Floyd Mayweather Jr.\\nCorona was the title sponsor of the LPGA Tour tournament Corona Championship (later Tres Marias Championship) from 2005 to 2009, and of the NASCAR Mexico Corona Series (now NASCAR PEAK Mexico Series) from 2004 to 2011, the most followed stock car racing series in Mexico.In addition, Corona is a \"second sponsor\" for four of the top-flight professional football teams of Mexico\\'s first division, Liga MX. The teams sponsored by Corona are Atlas, Santos Laguna, Quertaro, Puebla, Chiapas, Amrica, Pachuca, Morelia, Len, Toluca, and Necaxa. Corona also sponsored the Mexico national football team.Corona and the Association of Tennis Professionals (ATP) had a 5year sponsorship in which Corona was the ATP\\'s premier worldwide sponsor. Corona was also the title sponsor of the SBK Superbike World Championship from 1998 until 2007.\\n\\nAdvertising\\nCorona (beer)\\nCorona commercials for both Corona Extra and Corona Light typically take place on a beach with the tagline \"Miles Away From Ordinary\" from 2000 to 2007. Since the early 2010s, the tagline \"Find Your Beach\" was used.\\nIn 1990, Corona debuted \"O Tannenpalm\" which celebrated the Holidays. It featured a whistling rendition of the popular Christmas song \"O Christmas Tree\" as the lights go on one of the palm trees. The commercial has been played every year ever since during the month of December.\\n\\nUse in cocktails\\nCorona (beer)\\nSome bars and restaurants serve a \"Coronarita\", a beer cocktail that consists of a bottle of Corona upturned to drain into a margarita.\\n\\nCOVID-19 pandemic\\nCorona (beer)\\nDuring the COVID-19 pandemic, the beer saw some controversy due to its similarity in name to coronaviruses. There was some reduction in the sales of the brand in China, but not in the United States (where the brand is much more popular than in China and where sales of the brand actually rose by 5% in early 2020), and the sales slump in China affected various brands, not just Corona. CNN reported that a survey by 5W Public Relations said that 38% of Americans would not buy Corona \"under any circumstances\" because they associate the name with the coronavirus outbreak, and another 14% said they would not order a Corona in public. The survey of 737 American beer drinkers over the age of 21 was conducted via phone on February 25 and 26, 2020. The PR firm\\'s news release said the survey was carried out \"regarding their opinions about the popular Mexican beer brand, Corona, as a result of the deadly COVID-19 coronavirus that\\'s spreading around the world\". However, the question responsible for the 38% statistic did not actually mention COVID-19 as a motivation, which might have instead simply indicated a preference for a different brand of beer. Among regular Corona drinkers, only 4% said they planned to stop drinking the brand. Snopes and FactCheck.org reported that the notion that the pandemic caused a sharp reduction in sales due to confusion over the name of the brand was simply false.Production of the brand was briefly suspended in April 2020 because of government orders to temporarily close businesses, although the sales of the brand had not been harmed by the brand name\\'s similarity with the virus\\' name. The company said that sales of the brand were up 8.9% in the first three months of 2020, and showed year-over-year growth of 24% in the first three weeks of March 2020, as American consumers were drinking more beer and alcoholic beverages while staying at home during the emerging pandemic.\\n\\nSummary\\nNASCAR Mexico Series\\nThe NASCAR Mexico Series (formerly NASCAR Corona Series and other names) is a NASCAR series in Mexico. It is the most prestigious stock car racing series in the country.\\n\\nOrigins (Desafo Corona)\\nNASCAR Mexico Series\\nThe Desafo Corona was established in 2004 by NASCAR Mexico, a joint-venture between NASCAR and Mexican entertainment group OCESA, with the idea of developing stock car racing in Mexico, and fueling a transition from the country\\'s historically Open-wheel car racing fan base to stock car racing.From 2004 to 2006, the Desafo Corona grew considerably in infrastructure, as well as in number of fans, drivers and sponsors.\\n\\nPresent\\nNASCAR Mexico Series\\nThe NASCAR Mexico Corona Series was officially presented at the 2006 Desafo Corona award ceremony. Toyota assumed naming rights in 2012, dubbing it the NASCAR Toyota Series.The series is one of three NASCAR-sanctioned international series, the others are the NASCAR Pinty\\'s Series and the NASCAR Whelen Euro Series. Following North American short-track racing trends to cut costs and unify rules among different tours, NASCAR is considering changes to the Canadian Tire and Corona Series where the two series adopt the Busch rules as to allow the competitors to use the same cars in NASCAR Busch Series races.\\nThe winner of the series championship received an invitation to the UNOH Battle at the Beach, formerly the Toyota All-Star Showdown. All other drivers may also attempt to qualify by entering the heat races.\\n\\n2016 hiatus\\nNASCAR Mexico Series\\nAfter the end of the 2015 season, the series was suspended supposedly due to the fact that organizers of the series wanted to instead support the Formula One Mexican Grand Prix, which had just been revived for 2015. Several of the teams and drivers that participated in the series moved to the Super Copa Telcel \"V8\" series.\\n\\n2017 return\\nNASCAR Mexico Series\\nIn October 2016 it was announced that the series would return with new sponsorship from PEAK Antifreeze, with an exhibition race that December to be followed by a full 2017 season.Also in 2017 two supporter series were created: the NASCAR FedEx Challenge Series and NASCAR Mikel\\'s Truck Series.\\nThe series lost its sponsorship with PEAK Antifreeze in 2023, which was when a playoff system was implemented to the series.\\n\\nMexico Series tracks\\nNASCAR Mexico Series\\nIn its 14 seasons, the NASCAR PEAK Mexico Series has used 16 tracks in 14 venues (two in Santiago de Quertaro and two in San Luis Potos). Currently, six oval tracks are used, only Autdromo Monterrey is a road circuit. Three tracks have been used in two configurations. Autdromo Monterrey long and frijol, Autdromo Hermanos Rodrguez in NASCAR Nationwide and oval, Autdromo Miguel E. Abed in a 2.75 km layout and oval.\\nAutdromo Potosino is the shortest track (0.804 km) and Autdromo Monterrey the longest (3.4 km).\\nSan Luis Potos is the venue with more races (34, 32 in Autdromo Potosino and 2 in Parque Tangamanga II)\\nNASCAR Mexico had powered the construction of oval tracks in Mxico, Autdromo Potosino was remodeled in 2001, Aguascalientes, Chiapas, Quertaro had new tracks for NASCAR events. In 2012, a speedway in Chihuahua was scheduled for inauguration.For 2013, a race in the Southwestern United States was held: a 75-lap, 75-mile (122 km) race at Phoenix International Raceway during the NASCAR Cup Series Subway Fresh Fit 500 weekend.\\n\\nCars\\nNASCAR Mexico Series\\nIn the first season, only General Motors (through its Pontiac division) and Dodge participated in the series. Ford made its debut in 2005 with its Mustang model, but since 2006, the Fusion is the Ford model entry. In 2009, Toyota started its participation with its Camry. The Mazda 6 was first entered in 2010.  As with the other NASCAR divisions in the United States, Dodge subsequently pulled its factory support and no longer participates in the Mexican series.\\nAlong with the other international series, the K&N Pro Series East and West, and the ARCA Menards Series, the Mexico Series has General Tire as an exclusive tire supplier.\\n\\nSpecifications\\nNASCAR Mexico Series\\nChassis: Steel tube frame with safety roll cage, must be NASCAR standards.\\nEngine Displacement: 5.7 L (5,700 cc) (350 in) V8.\\nTransmission: 4 Speed Manual.\\nWeight: 2,680 lb (1,216 kg) Minimum (without driver).\\nPower Output: 400 hp.\\nTorque: 394 ftlbf (534 Nm).\\nFuel: 98 octane unleaded gasoline provided by Pemex.\\nFuel capacity: 15 US gal (57 L).\\nFuel delivery: Carburetion.\\nCompression ratio: 9.3:1.\\nAspiration: Naturally aspirated.\\nWheelbase: 107 in (2,718 mm).\\nTires: Slick tires provided by General Tire.\\nLength: 205.25 in (5,213 mm).\\nWidth: 74 in (1,880 mm).\\nHeight: 52 in (1,321 mm).\\nSafety equipment: HANS device, Seat belt.\\n\\nChampions\\nNASCAR Mexico Series\\nSix drivers have won the championship. The Telcel team is the most successful with four drivers\\' championships. Rubn Garca, Jr. is the youngest champion (20 years old), and Rafael Martnez the eldest. (45 years old). Germn Quiroga has the most championships to his name at 3.\\n\\nList of winners\\nNASCAR Mexico Series\\nUpdated after 2022 Monterrey2 (November 27, 2022)\\n\\nUniversity of Northwestern Ohio Battle at the Beach\\nNASCAR Mexico Series\\nMexico Series champions are invited to the NASCAR Toyota All-Star Showdown (now the University of Northwestern Ohio Battle at the Beach). In 2011 Daniel Surez, Germn Quiroga and Rubn Rovelo took part. They finished in 11th, 12th and 30th, respectly.The 2012 Series champion, along with international counterparts in Canada and Europe, will be invited to participate with an automatically exempt entry in any of the three divisions (Late Model, K&N Pro, Whelen Modified) in the Battle at the Beach, which will be held a week and a half before the series race at Phoenix International Raceway.\\n\\nFemale drivers\\nNASCAR Mexico Series\\nTo date, three women have started a NCS race. Mara Reyes scored a pole position in her first race.\\n\\nOther NASCAR series\\nNASCAR Mexico Series\\nSome drivers of NASCAR PEAK Mexico Series have taken part in Xfinity Series and Gander RV & Outdoors Truck Series action, but only Jorge Goeters and Daniel Surez have both raced in the NASCAR Cup Series and NASCAR PEAK Mexico Series. Scott Riggs, Cody Ware, Kevin O\\'Connell all of them only made one start in PEAK Mexico Series but also had run in both series. Rubn Pardo, Rogelio Lpez and Rubn Garca Jr. have won in the K&N Pro Series East; while Daniel Surez have won in the K&N Pro Series East, the NASCAR Xfinity Series, NASCAR Gander Outdoors Truck Series and NASCAR Cup Series. In 2016, Surez won the NASCAR Xfinity Series championship, driving for Joe Gibbs Racing. In 2017 and 2018, he moved to the NASCAR Cup Series driving No. 19 for Joe Gibbs Racing. In 2019, he moved to the No. 41 driving for Stewart-Haas Racing before moving to the No. 96 driving for Gaunt Brothers Racing, then moved to the No. 99 for Trackhouse Racing Team. On June 12th, 2022, Surez won his first career NASCAR Cup Series race at Sonoma Raceway.\\n\\nNASCAR Cup Series drivers\\nNASCAR Mexico Series\\nFive drivers have raced both the NASCAR PEAK Mexico and NASCAR Cup Series.\\n\\nSummary\\nCoronavirus\\nCoronaviruses are a group of related RNA viruses that cause diseases in mammals and birds. In humans and birds, they cause respiratory tract infections that can range from mild to lethal. Mild illnesses in humans include some cases of the common cold (which is also caused by other viruses, predominantly rhinoviruses), while more lethal varieties can cause SARS, MERS and COVID-19, which is causing the ongoing pandemic. In cows and pigs they cause diarrhea, while in mice they cause hepatitis and encephalomyelitis.\\nCoronaviruses constitute the subfamily Orthocoronavirinae, in the family Coronaviridae, order Nidovirales and realm Riboviria. They are enveloped viruses with a positive-sense single-stranded RNA genome and a nucleocapsid of helical symmetry. The genome size of coronaviruses ranges from approximately 26 to 32 kilobases, one of the largest among RNA viruses. They have characteristic club-shaped spikes that project from their surface, which in electron micrographs create', doc_id='8c2503e3-a267-44b3-a9eb-d6fef4ec8f2b', extra_info=None, node_info={'start': 0, 'end': 13857}, similarity=0.8636903414133754, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Question:Do you know Corona beer \\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec68f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 620 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 15 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sorry I don't know.\n",
      "[SourceNode(source_text='Kwak provides following products: Kwak Amber, Kwak Blonde, Kwak Rouge\\n\\n\\nBrand Introduction\\nPauwel Kwak was a brewer and owner of the De Hoorn Inn in Dendermonde at the time of Napoleon. He was also a very inventive innkeeper.\\nDuring those times, coachmen who stopped at an inn were not allowed to leave their coach and horses in order to have their thirst quenched, unlike their passengers. So Pauwel Kwak came up with an ingenious solution. He commissioned a special Kwak glass to be blown, a glass that could be hung safely on a coach. Allowing any coachman who visited his inn to enjoy a Kwak glass of beer like everyone else. His invention was a runaway success.\\nIn 1982 inspired by this tale, Ivo Bosteels created a special Pauwel Kwak amber beer and recreated his iconic glass design, so that the legacy of this unconventional genius continues to be enjoyed today.\\nIn 2022 the Kwak range expanded and the original Kwak Amber beer was joined by two new beers: Kwak Blonde and Kwak Rouge.\\n\\n\\nBrand Products\\nKwak Amber\\nKwak is a traditional strong Belgian amber ale, a perfect blend of malt and hops with a wonderful complexity of flavour. Original in its light amber colour with a full and velvety head, is this an ale with a beautiful explosion in the mouth of biscuit, banana, orange marmalade, hints of caramel and spices to end in a delicate bitterness.\\nABV: 8.4%\\nAroma: biscuit, banana, caramel, orange marmelade, spice, delicate bitterness\\n\\nKwak Blonde\\nKwak Blonde is a smooth and refreshing blonde beer, with delicate bitterness and subtle hints of aroma hops, a firm head and, above all, the characteristic fruitiness of the Kwak yeast, expressed in hints of banana and pear.\\nABV: 7.4%\\nAroma: delicate bitterness, banana, pear\\n\\nKwak Rouge\\nKwak rouge is a refreshing specialty beer with notes of cherry and almond, based on the unique Kwak recipe. Subtly bitter, slightly sweet and full of flavour.\\nABV: 8%\\nAroma: delicate bitterness, cherry, almond ', doc_id='e412f29c-f030-423a-86a9-5cc2913f34af', extra_info=None, node_info={'start': 0, 'end': 1964}, similarity=0.8126417392025518, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Question:Recommand some beer from Heineken please \\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d86284",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = bot.query('Question:Recommand some beer from Heineken please \\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e93a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd291f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4048 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 20 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorry, I don't know the specific Heineken beers you are referring to, but some popular Heineken beers include Goose Island IPA, Goose Island Gagga Goose, and Punch Cat Mango Flip. They all have different flavor profiles and alcohol content, ranging from 5.9% vol. to 5.5% vol. and IBU levels from 14 to 55.\n",
      "[SourceNode(source_text='IPA\\n\\n\\n\\n4.6%\\n 5%vol11.3P\\n100%5%vol11P\\n18924.5%vol10.2P142019~2020\\n4.5% vol.15 IBU\\n\\n\\n\\n4.5% vol.15 IBU\\n5.0%vol35IBU\\n5%vol20\\n\\n\\n\\n4.5%vol11.7P15\\n2.5%vol10.0P\\n13631516/5%vol11.75P\\n3123124.2%vol18IBU\\n4.8% vol.14 IBU\\n\\n\\nIPA\\nIPAIPA5.9%vol55IBUIPA\\nIPAIPA4.7%vol20IBU20196\\nIPA5.5% vol.40', doc_id='ac739f1a-2296-41ee-9009-91d55918f330', extra_info=None, node_info={'start': 0, 'end': 1776}, similarity=0.8252839306456214, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Question:Heineken \\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87ae018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4123 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 22 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorry, I don't know. However, some popular Maotai brands include the Goose Island IPA, Goose Island Gagaga Goose, and Punch Cat Mango Flip. The Goose Island IPA has a citrus and hop flavor, with an alcohol content of 5.9% vol. and an IBU of 55. The Goose Island Gagaga Goose is a light IPA with West Coast and Simcoe hops, with an alcohol content of 4.7% vol. and an IBU of 20. The Punch Cat Mango Flip is a mango hazy IPA with a tropical fruit flavor and a beer-like texture, with an alcohol content of at least 5.5% vol. and an IBU of 40.\n",
      "[SourceNode(source_text='IPA\\n\\n\\n\\n4.6%\\n 5%vol11.3P\\n100%5%vol11P\\n18924.5%vol10.2P142019~2020\\n4.5% vol.15 IBU\\n\\n\\n\\n4.5% vol.15 IBU\\n5.0%vol35IBU\\n5%vol20\\n\\n\\n\\n4.5%vol11.7P15\\n2.5%vol10.0P\\n13631516/5%vol11.75P\\n3123124.2%vol18IBU\\n4.8% vol.14 IBU\\n\\n\\nIPA\\nIPAIPA5.9%vol55IBUIPA\\nIPAIPA4.7%vol20IBU20196\\nIPA5.5% vol.40', doc_id='ac739f1a-2296-41ee-9009-91d55918f330', extra_info=None, node_info={'start': 0, 'end': 1776}, similarity=0.7974696859476827, image=None)]\n"
     ]
    }
   ],
   "source": [
    "r = bot.query('Question: \\nAnswer:', text_qa_template = DEFAULT_TEXT_QA_PROMPT)\n",
    "print(r)\n",
    "print(r.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "432ce08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.9 MB 163.8 kB/s eta 0:00:12\n",
      "      --------------------------------------- 0.0/1.9 MB 164.3 kB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.1/1.9 MB 233.8 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.1/1.9 MB 286.7 kB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.1/1.9 MB 275.8 kB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.1/1.9 MB 327.4 kB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.2/1.9 MB 403.5 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.2/1.9 MB 492.1 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.3/1.9 MB 571.2 kB/s eta 0:00:03\n",
      "     ------- -------------------------------- 0.4/1.9 MB 675.0 kB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 0.5/1.9 MB 810.2 kB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.6/1.9 MB 878.6 kB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.6/1.9 MB 914.3 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.7/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 0.8/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 0.9/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 1.1/1.9 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.4/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.6/1.9 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\desktop\\abi_chatbot\\specialized_chatbot\\.venv\\lib\\site-packages (from langid) (1.23.5)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py): started\n",
      "  Building wheel for langid (setup.py): finished with status 'done'\n",
      "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941179 sha256=42e8ed1fd660e4d51c93303d26bd2e45ef3f4b3e1b00a19eb902231250fe9e5a\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\32\\6a\\b6\\b7eb43a6ad55b139c15c5daa29f3707659cfa6944d3c696f5b\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff84d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "import json\n",
    "\n",
    "with open(\"data/lang_code.json\", 'r') as f:\n",
    "    lang_code = json.load(f) \n",
    "\n",
    "def lang_detect(text:str)->str:\n",
    "    \"\"\"detect language\n",
    "    Parameter:\n",
    "    --------\n",
    "        text: str\n",
    "            the text for which the langudate you want to detect\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "        langudge\n",
    "    \"\"\"\n",
    "    # Language detection\n",
    "    try:\n",
    "        code = langid.classify(text)[0]\n",
    "        lang = lang_code[code]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        lang = 'English'\n",
    "    return lang\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c7beb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85059258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_code['zh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d6e4ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_llm': OpenAI(cache=None, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x0000023F436EE0D0>, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False),\n",
       " 'retry_on_throttling': True,\n",
       " '_total_tokens_used': 38503,\n",
       " 'flag': True,\n",
       " '_last_token_usage': 4048}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.llm_predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fc4c5ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPTSimpleVectorIndex' object has no attribute 'lang_detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang_detect\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPTSimpleVectorIndex' object has no attribute 'lang_detect'"
     ]
    }
   ],
   "source": [
    "bot.lang_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fa6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
